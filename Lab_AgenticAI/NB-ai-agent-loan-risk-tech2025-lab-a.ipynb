{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# Tech 2025 Lab\n### Lab A - Loan Risk AI Agent\nAn **AI Agent** refers to a system or program that is capable completing a request by first planning the sequence of workflow steps and then performing the tasks in the steps by utilizing available tools. AI agents utilizes large language models (LLM) to understand the context of the request, plan and perform the tasks. \n\nThis Python Notebook provides the code to create a simple AI agent for risk and interest rate evaluation in a bank loan processing scenario. It uses LangGraph graph for state and runtime processing. Once created, you assume the persona of a loan risk analyst at a bank and ask the Loan Risk AI Agent questions in natural language to assess risks for customers. When a question is asked, the AI agent will use a LLM to understand the context, determine the seqence of steps, and then complete the steps utilizing availble tools. The tools fetch customer information, credit score, account status and determine risk and interest rate. The sequence of steps, tool calling and final response can be reviewed in the output.\n\n#### To use this Notebook:\n\nRun each cell below one by one and make sure it completes successfully.\n\nWhen prompted for API key enter it in the box and hit Enter and then continue running the cells to initialize the code.\n\nFinally, when prompted enter your query and run the subsequent cells. Some example questions are provided.\n\nYou may run/repeat the query cells by entering and trying different queries.", "metadata": {"id": "4be62f6a-4776-4dc9-b6db-9673f06bc388"}}, {"cell_type": "markdown", "source": "#### Lab A - Exercise 1\nBelow is an outline of the code. The code is set up in Python Notebook cells.\n\n1. Set up required libraries\n2. Define functions to get and check credentials\n3. Define tools that the AI agent can use\n4. Configure the LLM\n5. Define the LangGraph graph and functions for state and runtime processing.\n6. Show a visual representation the graph - the AI agent with tools\n7. Use the AI agent - ask the AI agent risk related question\n8. Review the responses from AI agent risk\n\n#### Lab A - Exercise 2\n1. Add another tool that can provide interest rate.\n2. Use the AI agent - ask the AI agent risk and interest rate related question\n3. Review the responses from AI agent risk\n\n\n#### Lab A - Exercise 3 (Optional)\n1. Update the overall risk and interest rate tools to use RAG (retrieval augmented generation) pattern based query determine risk and interest rate.\n2. Use the AI agent - ask the AI agent risk and interest rate related question\n3. Review the responses from AI agent risk\n\n\n~TBD cell bookmarks for above. Example, not working.\n\n<a href='#lab_a_exercise_2'>Lab A - Exercise 2</a>\n\n[Lab A - Exercise 2](#lab_a_exercise_2)\n", "metadata": {"id": "609b3c27-f6dc-4daf-8101-7a3b38791717"}}, {"cell_type": "markdown", "source": "### Lab A - Exercise 1", "metadata": {"id": "956b5a54-4eb6-424f-83cc-1f6c15af4aa4"}}, {"cell_type": "markdown", "source": "#### 1. Set up required libraries", "metadata": {"id": "1f742f2c-386c-4094-874a-9be788685811"}}, {"cell_type": "code", "source": "# Set up libraries\n%pip install langgraph==0.2.73\n%pip install -U langchain-ibm==0.3.6\n    \nfrom typing import Annotated, Literal, TypedDict\n\nfrom langchain_core.messages import HumanMessage\n\nfrom langchain_core.tools import tool\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.graph import END, START, StateGraph, MessagesState\nfrom langgraph.prebuilt import ToolNode\n\nimport requests\nimport json\nimport time\nimport random", "metadata": {"id": "ac1bb4df-737d-45fb-9e14-6bdc75bad441", "scrolled": true}, "outputs": [{"name": "stdout", "text": "Requirement already satisfied: langgraph==0.2.73 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (0.2.73)\nRequirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langgraph==0.2.73) (0.3.43)\nRequirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langgraph==0.2.73) (2.0.18)\nRequirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langgraph==0.2.73) (0.1.51)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (0.1.126)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (8.2.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (1.33)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (6.0.1)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (23.2)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (4.11.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (2.8.2)\nRequirement already satisfied: msgpack<2.0.0,>=1.1.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph==0.2.73) (1.1.0)\nRequirement already satisfied: httpx>=0.25.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.73) (0.26.0)\nRequirement already satisfied: orjson>=3.10.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.73) (3.10.2)\nRequirement already satisfied: anyio in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.73) (3.5.0)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.73) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.73) (1.0.2)\nRequirement already satisfied: idna in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.73) (3.7)\nRequirement already satisfied: sniffio in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.73) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.73) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (3.0.0)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (2.32.2)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (0.6.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (1.26.19)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: langchain-ibm==0.3.6 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (0.3.6)\nRequirement already satisfied: ibm-watsonx-ai<2.0.0,>=1.1.16 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-ibm==0.3.6) (1.2.8)\nRequirement already satisfied: langchain-core<0.4,>=0.3.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-ibm==0.3.6) (0.3.43)\nRequirement already satisfied: requests in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (2.32.2)\nRequirement already satisfied: httpx in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (0.26.0)\nRequirement already satisfied: urllib3 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (1.26.19)\nRequirement already satisfied: pandas<2.2.0,>=0.24.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (2.1.4)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (2025.1.31)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (0.3.3)\nRequirement already satisfied: tabulate in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (0.8.10)\nRequirement already satisfied: packaging in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (23.2)\nRequirement already satisfied: ibm-cos-sdk<2.14.0,>=2.12.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (2.13.4)\nRequirement already satisfied: importlib-metadata in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (7.0.1)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (0.1.126)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (8.2.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (1.33)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (6.0.1)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (4.11.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (2.8.2)\nRequirement already satisfied: ibm-cos-sdk-core==2.13.4 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (2.13.4)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.13.4 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (2.13.4)\nRequirement already satisfied: jmespath<=1.0.1,>=0.10.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (1.0.1)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-cos-sdk-core==2.13.4->ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (2.8.2)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (3.10.2)\nRequirement already satisfied: anyio in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpx->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (3.5.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpx->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (1.0.2)\nRequirement already satisfied: idna in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpx->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (3.7)\nRequirement already satisfied: sniffio in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpx->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpcore==1.*->httpx->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (0.14.0)\nRequirement already satisfied: numpy<2,>=1.23.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (1.26.4)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (2024.1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (2023.3)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (0.6.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (2.0.4)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from importlib-metadata->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (3.20.2)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from lomond->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n", "output_type": "stream"}], "execution_count": 29}, {"cell_type": "markdown", "source": "#### 2. Define functions to get and check credentials", "metadata": {"id": "c376e0e3-76f0-4079-b382-995410034157"}}, {"cell_type": "code", "source": "# Function to get credentials\nimport getpass\nimport os\n\ndef _set_if_undefined(var: str):\n    if not os.environ.get(var):\n        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n\n# Get credentials\n# Set the Project IDs\n# If using you own account, or lab account and project, the current project id will be configured and set automtically\n_set_if_undefined(\"PROJECT_ID\")\n\n# When prompted for API key enter it in the box and hit Enter, move to next cell and then continue running the cells\n_set_if_undefined(\"WATSONX_API_KEY\")\n", "metadata": {"id": "52a152ce-7efd-45f2-b5df-4ce5ea5efab7"}, "outputs": [], "execution_count": 30}, {"cell_type": "code", "source": "# Print credential configurations for validation\nprint('Api key:',os.environ.get(\"WATSONX_API_KEY\"))\nprint('Project id:',os.environ.get(\"PROJECT_ID\"))", "metadata": {"id": "069d3ba7-2788-4f3d-9083-df43c0495ff8"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "#### 3. Define tools that the AI agent can use", "metadata": {"id": "eb45e773-d3c9-42ca-b349-d062d808e596"}}, {"cell_type": "code", "source": "# Define tools that the AI agent can use\n\n# The tool get_customer_info() simulates/mocks API call that fetches credit score and account status information about a customer\n# The tools get_credit_score() and get_account_status() use the customer info tool to get the score and account status\n# The customer's loan risk is determined based on credit score and account status risk rules using get_overall_risk() tool\n# When a natural language question is asked, the AI agent first determines the context and then the sequence to utilize one or more tools to provide a response \n\n# this tool simulates an API call that will fetch information about customers\n@tool\ndef get_customer_info(customer_id: str): \n    \"\"\"Retrieve customer information based on the customer_id.\"\"\"\n    customer_id = customer_id.lower()\n    \n    if customer_id in ['loren@ibm.com', 'loren', '1111']:\n        return {'credit_score': 455, 'account_status': 'good-standing'}\n    elif customer_id in ['matt@ibm.com', 'matt', '2222']:\n        return {'credit_score': 685, 'account_status': 'closed'}\n    elif customer_id in ['hilda@ibm.com', 'hilda', '3333']:\n        return {'credit_score': 825, 'account_status': 'delinquent'}\n    else:\n        #return {'credit_score': None, 'account_status': None}\n        #if any other customer id is used, provide a random credit score and account status\n        return {'credit_score': random.randint(300, 850), 'account_status': random.choice(['delinquent', 'good-standing', 'closed' ])}\n\n\n\n# this tool fetches credit score of a customer\n@tool\ndef get_credit_score(customer_id: str) -> int: \n    \"\"\"Get the credit score for the customer using customer_id. Customer's name can be used instead of customer_id.\"\"\"\n    customer_info = get_customer_info(customer_id)\n    return customer_info['credit_score']\n    customer_id = customer_id.lower()\n\n\n# this tool fetches account status of a customer\n@tool\ndef get_account_status(customer_id: str) -> str: \n    \"\"\"Get the account status for the customer using customer_id. Customer's name can be used instead of customer_id.\"\"\"\n    customer_info = get_customer_info(customer_id)\n    return customer_info['account_status']\n    customer_id = customer_id.lower()\n\n# this tool determines the overall risk for a customer\n@tool\ndef get_overall_risk(credit_score: int, account_status: str):\n    \"\"\"Get overall risk based on combination of both credit score and account status. Only use high, medium or low as risk categories. Explain how the overall risk was calculated. If the credit score and account status are unknown then do not provide the risk status and first retrieve the missing credit score or account status.\"\"\"\n\n    #print(\"get_overall_risk():credit score:account status::\", credit_score, account_status)\n    \n    if (credit_score > 299 & credit_score < 674): \n        if (account_status == 'delinquent'): overall_risk = 'high'\n        elif (account_status == 'closed'):  overall_risk = 'high'\n        elif (account_status == 'good-standing'):  overall_risk = 'medium'\n        else: overall_risk = 'unkown'\n    \n    elif (credit_score >= 675 & credit_score < 749): \n        if (account_status == 'delinquent'): overall_risk = 'high'\n        elif (account_status == 'closed'):  overall_risk = 'medium'\n        elif (account_status == 'good-standing'):  overall_risk = 'medium'\n        else: overall_risk = 'unkown'\n\n    elif (credit_score >= 750 & credit_score < 851): \n        if (account_status == 'delinquent'): overall_risk = 'high'\n        elif (account_status == 'closed'):  overall_risk = 'low'\n        elif (account_status == 'good-standing'):  overall_risk = 'low'\n        else: overall_risk = 'unkown'\n    \n\n    else: overall_risk = 'unable to determine.'    \n    return overall_risk\n\n# Set the list of tools to be used by the AI agent\ntools = [get_credit_score, get_account_status, get_overall_risk, get_customer_info]\n\ntool_node = ToolNode(tools)\n\n", "metadata": {"id": "4aaf0378-a97b-4774-bc8d-855f75c9e3f9"}, "outputs": [], "execution_count": 32}, {"cell_type": "markdown", "source": "#### 4. Configure the LLM", "metadata": {"id": "479bcf27-bfab-4602-9cbc-842311bb64c6"}}, {"cell_type": "code", "source": "#Configure the LLM\n\nfrom ibm_watsonx_ai.metanames import GenTextParamsMetaNames\nparameters = {\n    GenTextParamsMetaNames.DECODING_METHOD: \"sample\", #\"greedy\", #\"sample\"\n    GenTextParamsMetaNames.MIN_NEW_TOKENS: 150,\n    GenTextParamsMetaNames.MAX_NEW_TOKENS: 250,\n    GenTextParamsMetaNames.TEMPERATURE: 0,\n    #GenTextParamsMetaNames.TOP_K: 50,\n    #GenTextParamsMetaNames.TOP_P: 1,\n}\n\nfrom langchain_ibm import ChatWatsonx\nmodel = ChatWatsonx(\n    model_id=\"mistralai/mistral-large\", \n    url=\"https://us-south.ml.cloud.ibm.com\", \n    #url=\"https://eu-de.ml.cloud.ibm.com\", \n    apikey=os.environ.get(\"WATSONX_API_KEY\"),\n    project_id=os.environ.get(\"PROJECT_ID\"),\n    params=parameters,\n).bind_tools(tools)", "metadata": {"id": "bbe66af5-01dd-44c2-9d61-c7cbc7758cf5"}, "outputs": [], "execution_count": 33}, {"cell_type": "markdown", "source": "#### 5. Define the LangGraph graph and functions for state and runtime processing.", "metadata": {"id": "0a89083d-9436-45ff-851d-6c5698c8b0f7"}}, {"cell_type": "code", "source": "# Define the function that determines whether to continue or not\ndef should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n    messages = state['messages']\n    last_message = messages[-1]\n    # If the LLM makes a tool call, then we route to the \"tools\" node\n    if last_message.tool_calls:\n        return \"tools\"\n    # Otherwise, we stop (reply to the user)\n    return END\n\n\n# Define the function that calls the model\ndef call_model(state: MessagesState):\n    messages = state['messages']\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\n", "metadata": {"id": "b2959dec-c28c-4ad5-82a0-d5ab8e33c8f8"}, "outputs": [], "execution_count": 34}, {"cell_type": "code", "source": "# Define a new graph\nworkflow = StateGraph(MessagesState)\n\n# Define the two nodes we will cycle between\nworkflow.add_node(\"agent\", call_model)\nworkflow.add_node(\"tools\", tool_node)\n\n# Set the entrypoint as `agent`\n# This means that this node is the first one called\nworkflow.add_edge(START, \"agent\")\n\n# add a conditional edge\nworkflow.add_conditional_edges(\n    # First, we define the start node. We use `agent`.\n    # This means these are the edges taken after the `agent` node is called.\n    \"agent\",\n    # Next, we pass in the function that will determine which node is called next.\n    should_continue,\n)\n\n# add a normal edge from `tools` to `agent`.\n# after `tools` is called, `agent` node is called next.\nworkflow.add_edge(\"tools\", 'agent')\n\n\n# Compile graph\napp = workflow.compile()\n", "metadata": {"id": "fd9f88ac-fc71-4939-8f09-8e3e719450e4"}, "outputs": [], "execution_count": 35}, {"cell_type": "markdown", "source": "#### 6. Show a visual representation the graph - the AI agent with tools", "metadata": {"id": "d05e046a-8d73-4a29-aa78-6b1c89b563c5"}}, {"cell_type": "code", "source": "# Show graph\nfrom IPython.display import display, Image\ndisplay(Image(app.get_graph().draw_mermaid_png()))", "metadata": {"id": "225b9451-fed0-4e61-9157-66ac42a0468d"}, "outputs": [{"output_type": "display_data", "data": {"image/png": "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", "text/plain": "<IPython.core.display.Image object>"}, "metadata": {}}], "execution_count": 36}, {"cell_type": "markdown", "source": "#### 7. Use the AI agent - ask the AI agent risk related question\n", "metadata": {"id": "6f8e1264-ad9d-43b1-a0f6-fc41292de435"}}, {"cell_type": "markdown", "source": "\nAsk the AI agent these questions. Review the response.\n\n- what can you do for me?\n- what can you do for me? how?\n\n- what is the risk for matt?\n \n- what is the risk for matt? explain why?\n\n- tell me about hilda?\n  \n- what is the risk for hilda? explain why?\n\n- what is the risk for credit score 774 and account status delinquent?\n\n- what is the risk for credit score 774 and account status delinquent? how was it determined?\n\nAlso try asking questions about interest rate....\n\n- what is the interest rate for matt?\n\n- what is the interest rate for matt? explain how it was determined?\n\nFor the last two questions, note that there is no tool yet that provides interest rate. So the response does not answer the question appropriately. \nWe will add interest rate tool in the next exercise.\n\n#### Write the query in the box and hit Enter and then continue running the next cells", "metadata": {"id": "eb5074ac-de5c-4cc9-ac2c-76b9fd92a900"}}, {"cell_type": "code", "source": "human_query = input(\"Type a question and hit enter: \")", "metadata": {"id": "ca269a6f-1ab0-4950-b27b-5101e52f052b"}, "outputs": [{"output_type": "stream", "name": "stdin", "text": "Type a question and hit enter:  what is the interest rate for matt? explain how it was determined?\n"}], "execution_count": 37}, {"cell_type": "code", "source": "# Use the runtime\nfinal_state = app.invoke(\n    #{\"messages\": [HumanMessage(content=\"what is the overall risk?\")]},\n    {\"messages\": [HumanMessage(content=human_query)]},\n    config={\"configurable\": {\"thread_id\": random.randint(1, 100)}}\n)\n\n#final_state[\"messages\"][-1].content\n\nfor m in final_state[\"messages\"]:\n    m.pretty_print()\n\n#Print final message\n#final_state[\"messages\"][-1].content\n", "metadata": {"id": "053a334b-5f12-4a92-ab05-7e22e84219c5"}, "outputs": [{"name": "stdout", "text": "================================\u001b[1m Human Message \u001b[0m=================================\n\nwhat is the interest rate for matt? explain how it was determined?\n==================================\u001b[1m Ai Message \u001b[0m==================================\nTool Calls:\n  get_customer_info (0gEdZwXvA)\n Call ID: 0gEdZwXvA\n  Args:\n    customer_id: matt\n=================================\u001b[1m Tool Message \u001b[0m=================================\nName: get_customer_info\n\n{\"credit_score\": 685, \"account_status\": \"closed\"}\n==================================\u001b[1m Ai Message \u001b[0m==================================\nTool Calls:\n  get_overall_risk (SE92znhWL)\n Call ID: SE92znhWL\n  Args:\n    credit_score: 685\n    account_status: closed\n=================================\u001b[1m Tool Message \u001b[0m=================================\nName: get_overall_risk\n\nhigh\n==================================\u001b[1m Ai Message \u001b[0m==================================\n\n The overall risk for Matt is high. This is determined by considering both the credit score and account status. A credit score of 685 is considered fair, and a closed account status indicates potential issues with the account. Combining these factors results in a high overall risk.\n", "output_type": "stream"}], "execution_count": 38}, {"cell_type": "markdown", "source": "#### 8. Review the response above from AI agent risk\nRun/repeat the above cells with different queries, i.e., rerun the human_query and final_state = app.invoke() cells with different queries", "metadata": {"id": "a14b6c66-53f5-4730-8428-24b398177176"}}, {"cell_type": "code", "source": "", "metadata": {"id": "6984b533-9b55-4e89-9bd2-75517e26e4cc"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "3900ccac-113d-4877-82c3-68690f7f3bc7"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "7207c88a-163e-4759-9c1f-c23a87ef6f32"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "<a id='lab_a_exercise_2'></a>\n### Lab A - Exercise 2\n", "metadata": {"id": "cdc2ebe1-36d1-4b66-83cd-6d8801a8dfb7"}}, {"cell_type": "markdown", "source": "So far we had tool that provided the risk level for a customer - as low, medium or high. There was no tool to provide a specific interest rate.\nIn this exercise we will add another tool that can provide the interest rate based on the risk level.\n", "metadata": {"id": "d00f3964-30f8-4451-89b6-46fb5a9ba8fe"}}, {"cell_type": "code", "source": "# this tool determines the interest rate for a customer\n@tool\ndef get_interest_rate(overall_risk: str):\n    \"\"\"Get interest rate percentage based on the overall risk. If the overall risk is not known then do not provide the interest rate and first retrieve the missing overall risk.\"\"\"\n    if (overall_risk.lower() == \"high\"):\n        interest_rate=10.75;\n    \n    elif (overall_risk.lower() == \"medium\"):\n        interest_rate=5.25;\n\n    elif (overall_risk.lower() == \"low\"):\n        interest_rate=3.0;\n    \n    else: interest_rate = 'unable to determine.'    \n    return interest_rate\n\n\n# Lets add/include this tool in the list of tools used by the AI agent in the following code line \"tools =...\"\ntools = [get_credit_score, get_account_status, get_overall_risk, get_interest_rate, get_customer_info]\ntool_node = ToolNode(tools)", "metadata": {"id": "907303b3-dbf0-42ec-9ba1-65c4d57a7004"}, "outputs": [], "execution_count": 40}, {"cell_type": "code", "source": "# Re-bind the model configuration with new tools\n\nfrom ibm_watsonx_ai.metanames import GenTextParamsMetaNames\nparameters = {\n    GenTextParamsMetaNames.DECODING_METHOD: \"sample\", #\"greedy\", #\"sample\"\n    GenTextParamsMetaNames.MIN_NEW_TOKENS: 150,\n    GenTextParamsMetaNames.MAX_NEW_TOKENS: 250,\n    GenTextParamsMetaNames.TEMPERATURE: 0,\n    #GenTextParamsMetaNames.TOP_K: 50,\n    #GenTextParamsMetaNames.TOP_P: 1,\n}\n\nfrom langchain_ibm import ChatWatsonx\nmodel = ChatWatsonx(\n    model_id=\"mistralai/mistral-large\", \n    url=\"https://us-south.ml.cloud.ibm.com\", \n    #url=\"https://eu-de.ml.cloud.ibm.com\", \n    apikey=os.environ.get(\"WATSONX_API_KEY\"),\n    project_id=os.environ.get(\"PROJECT_ID\"),\n    params=parameters,\n).bind_tools(tools)", "metadata": {"id": "83b40917-602b-4725-8b64-799788371f55"}, "outputs": [], "execution_count": 41}, {"cell_type": "code", "source": "# Re-define the function that determines whether to continue or not\ndef should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n    messages = state['messages']\n    last_message = messages[-1]\n    # If the LLM makes a tool call, then we route to the \"tools\" node\n    if last_message.tool_calls:\n        return \"tools\"\n    # Otherwise, we stop (reply to the user)\n    return END\n\n\n# Re-define the function that calls the model\ndef call_model(state: MessagesState):\n    messages = state['messages']\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}", "metadata": {"id": "fa1564b2-b055-4c9c-8ed1-f7cdb037a74b"}, "outputs": [], "execution_count": 42}, {"cell_type": "code", "source": "# Re-define a new graph with new tools\nworkflow = StateGraph(MessagesState)\n\n# Re-define the two nodes we will cycle between\nworkflow.add_node(\"agent\", call_model)\nworkflow.add_node(\"tools\", tool_node)\n\n# Set the entrypoint as `agent`\n# This means that this node is the first one called\nworkflow.add_edge(START, \"agent\")\n\n# add a conditional edge\nworkflow.add_conditional_edges(\n    # First, we define the start node. We use `agent`.\n    # This means these are the edges taken after the `agent` node is called.\n    \"agent\",\n    # Next, we pass in the function that will determine which node is called next.\n    should_continue,\n)\n\n# add a normal edge from `tools` to `agent`.\n# after `tools` is called, `agent` node is called next.\nworkflow.add_edge(\"tools\", 'agent')\n\n\n# Re-compile graph\napp = workflow.compile()\n", "metadata": {"id": "9803104c-883a-419a-b727-d5b809c22ce8"}, "outputs": [], "execution_count": 43}, {"cell_type": "markdown", "source": "\nAsk the AI agent questions about interest rate. Review the response.\n\n \n- what is the interest rate for matt?\n\n- what is the interest rate for matt? explain how it was determined?\n\nNote that how the AI agent can now use the get_interest_rate to provide interest rate also.\n\n#### Write the query in the box and hit Enter and then continue running the next cells", "metadata": {"id": "7bbd99ea-9163-4e69-a238-cd9bd70b1dd9"}}, {"cell_type": "code", "source": "human_query = input(\"Type a question and hit enter: \")\n", "metadata": {"id": "5799519a-abd5-47cd-b394-35e0554cc744"}, "outputs": [{"output_type": "stream", "name": "stdin", "text": "Type a question and hit enter:  what is the interest rate for matt? explain how it was determined?\n"}], "execution_count": 44}, {"cell_type": "code", "source": "# Use the runtime\nfinal_state = app.invoke(\n    #{\"messages\": [HumanMessage(content=\"what is the overall risk?\")]},\n    {\"messages\": [HumanMessage(content=human_query)]},\n    config={\"configurable\": {\"thread_id\": random.randint(1, 100)}}\n)\n\n#final_state[\"messages\"][-1].content\n\nfor m in final_state[\"messages\"]:\n    m.pretty_print()\n\n#Print final message\n#final_state[\"messages\"][-1].content", "metadata": {"id": "f9551a68-cd7e-44ab-b820-64e266ad3611"}, "outputs": [{"name": "stdout", "text": "================================\u001b[1m Human Message \u001b[0m=================================\n\nwhat is the interest rate for matt? explain how it was determined?\n==================================\u001b[1m Ai Message \u001b[0m==================================\nTool Calls:\n  get_customer_info (MxwzVlSyy)\n Call ID: MxwzVlSyy\n  Args:\n    customer_id: matt\n=================================\u001b[1m Tool Message \u001b[0m=================================\nName: get_customer_info\n\n{\"credit_score\": 685, \"account_status\": \"closed\"}\n==================================\u001b[1m Ai Message \u001b[0m==================================\nTool Calls:\n  get_overall_risk (cyhA7Rzsg)\n Call ID: cyhA7Rzsg\n  Args:\n    credit_score: 685\n    account_status: closed\n=================================\u001b[1m Tool Message \u001b[0m=================================\nName: get_overall_risk\n\nhigh\n==================================\u001b[1m Ai Message \u001b[0m==================================\nTool Calls:\n  get_interest_rate (8S8EUh32D)\n Call ID: 8S8EUh32D\n  Args:\n    overall_risk: high\n=================================\u001b[1m Tool Message \u001b[0m=================================\nName: get_interest_rate\n\n10.75\n==================================\u001b[1m Ai Message \u001b[0m==================================\n\n The interest rate for Matt is 10.75%. This was determined based on the overall risk assessment, which was categorized as high. The high risk category was assigned due to a credit score of 685 and a closed account status.\n", "output_type": "stream"}], "execution_count": 45}, {"cell_type": "code", "source": "", "metadata": {"id": "d606aec0-2b2f-4cef-b56a-73dddf56a464"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "10e0c369-ead5-45ac-9b3c-c0ee10f3243a"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "686c3630-b75c-4c25-8b01-1613b20c82e1"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "### Lab A - Exercise 3 (Optional) \n\n### ***** this exercise will be made demo only due to time constraints and complexities in creating RAG deployments and endpoints in every project ****", "metadata": {"id": "d3ccbc0f-be1a-43ca-82e6-5c217a747a0b"}}, {"cell_type": "markdown", "source": "In this exercise will use RAG (retrieval augmented generation) pattern based query determine risk and interest rate. Instead of conditions defined in the tool,  content in the published risk and interest rate documents will be used to determine the risk and interest rate. \nFor reference, these documents can be found here. They were used to create embeddings and vector index for RAG querying.\nThe RAG URL endpoint to get risk and interest rate was pre-created and will be called from the new tools.\n\nIN the following cells, we will create new rag llm based risk and interest rate tools and set up the AI agent to use them.\n", "metadata": {"id": "2f8a9074-1bee-406e-b0b8-af12c26a963d"}}, {"cell_type": "code", "source": "# Calling the RAG LLM endpoint requires a bearer token. First we will create the code that will be used to get the IBM IAM bearer token from API key\n# Function to get IBM IAM bearer token\nos.environ[\"IBM_IAM_ACCESS_TOKEN_EXPIRATION\"]=\"1\" #must be initialized for validaiton purposes\ndef get_ibm_iam_token() -> str: \n    epoch_time = int(time.time())\n    #print(epoch_time)\n    if ( int(os.environ[\"IBM_IAM_ACCESS_TOKEN_EXPIRATION\"]) < epoch_time):\n        #print(\"IBM_IAM_ACCESS_TOKEN expired.\")\n    \n        #get new token\n        url = \"https://iam.cloud.ibm.com/identity/token\"\n        headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n        data = 'grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey='+os.environ.get(\"WATSONX_API_KEY\")\n        try:\n            response = requests.post(url, data=data, headers=headers)\n            response.raise_for_status()\n            #print(response.json())\n            os.environ[\"IBM_IAM_ACCESS_TOKEN\"]=response.json()[\"access_token\"]\n            os.environ[\"IBM_IAM_ACCESS_TOKEN_EXPIRATION\"]=str(response.json()[\"expiration\"])\n    \n        except requests.exceptions.RequestException as e:\n            print(f\"An error occurred: {e}\")\n    \n    #else:\n        #print(\"IBM_IAM_ACCESS_TOKEN is valid.\")\n        #print(\"IBM_IAM_ACCESS_TOKEN:\",os.environ[\"IBM_IAM_ACCESS_TOKEN\"])\n        #print(\"IBM_IAM_ACCESS_TOKEN_EXPIRATION:\",os.environ[\"IBM_IAM_ACCESS_TOKEN_EXPIRATION\"])\n\n    return os.environ[\"IBM_IAM_ACCESS_TOKEN\"]\n#print(get_ibm_iam_token())", "metadata": {"id": "085d2e79-df7e-46c6-be8b-8b22c39a4f7c"}, "outputs": [], "execution_count": 22}, {"cell_type": "code", "source": "# this tool determines the overall risk for a customer using a RAG endpoint\n@tool\ndef get_overall_risk_from_rag_llm(credit_score:int, account_status:str):\n    \"\"\"Get overall risk based on combination of both credit score and account status. Explain how the overall risk was calculated. If the credit score and account status are not known then do not provide the risk status and first retrieve the missing credit score or account status.\"\"\"\n    rag_url = \"https://us-south.ml.cloud.ibm.com/ml/v4/deployments/61b4776a-a77d-457e-b44d-c83a3b3456ad/ai_service?version=2021-05-01\"\n    headers = {'Content-type': 'application/json', 'Authorization': 'Bearer ' + get_ibm_iam_token() }\n    llm_rag_query=\"what is the risk for credit score \" + str(credit_score) + \" and account status \" + account_status + \", and how is it determined?\",\n    data = {\"messages\": [{\"content\": llm_rag_query,\"role\": \"user\" }]}\n    \n    try:\n        response = requests.post(rag_url, data=json.dumps(data), headers=headers)\n        response.raise_for_status()\n        #print(response.json())\n    except requests.exceptions.RequestException as e:\n        print(f\"An error occurred: {e}\")\n\n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n\n# this tool determines the interest rate for a customer using a RAG endpoint\n@tool\ndef get_interest_rate_from_rag_llm(overall_risk:str):\n    \"\"\"Get interest rate percentage based on overall risk. If the overall risk is not known then do not provide the interest rate status and first retrieve the overall risk. Explain how the interest rate was determined.\"\"\"\n\n    rag_url = \"https://us-south.ml.cloud.ibm.com/ml/v4/deployments/61b4776a-a77d-457e-b44d-c83a3b3456ad/ai_service?version=2021-05-01\"\n    headers = {'Content-type': 'application/json', 'Authorization': 'Bearer ' + get_ibm_iam_token() }\n    llm_rag_query=\"what is the interest rate for overall risk \" + overall_risk + \", and how is it determined?\",\n    data = {\"messages\": [{\"content\": llm_rag_query,\"role\": \"user\" }]}\n    \n    try:\n        response = requests.post(rag_url, data=json.dumps(data), headers=headers)\n        response.raise_for_status()\n        #print(response.json())\n    except requests.exceptions.RequestException as e:\n        print(f\"An error occurred: {e}\")\n\n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n\n\n# Set the list of tools to be used by the AI agent - - we change the risk and interest rate tools to use the ones with rag_llm\ntools = [get_credit_score, get_account_status, get_overall_risk_from_rag_llm, get_interest_rate_from_rag_llm, get_customer_info]\n\ntool_node = ToolNode(tools)\n", "metadata": {"id": "c007a959-b4d7-4577-b14b-c36f997e3431"}, "outputs": [], "execution_count": 23}, {"cell_type": "code", "source": "# Re-bind the model configuration with new tools\nfrom ibm_watsonx_ai.metanames import GenTextParamsMetaNames\nparameters = {\n    GenTextParamsMetaNames.DECODING_METHOD: \"sample\", #\"greedy\", #\"sample\"\n    GenTextParamsMetaNames.MIN_NEW_TOKENS: 150,\n    GenTextParamsMetaNames.MAX_NEW_TOKENS: 250,\n    GenTextParamsMetaNames.TEMPERATURE: 0,\n    #GenTextParamsMetaNames.TOP_K: 50,\n    #GenTextParamsMetaNames.TOP_P: 1,\n}\n\nfrom langchain_ibm import ChatWatsonx\nmodel = ChatWatsonx(\n    model_id=\"mistralai/mistral-large\", \n    url=\"https://us-south.ml.cloud.ibm.com\", \n    #url=\"https://eu-de.ml.cloud.ibm.com\", \n    apikey=os.environ.get(\"WATSONX_API_KEY\"),\n    project_id=os.environ.get(\"PROJECT_ID\"),\n    params=parameters,\n).bind_tools(tools)", "metadata": {"id": "e10f446a-8ba1-4401-9af2-4186db91a80e"}, "outputs": [], "execution_count": 24}, {"cell_type": "code", "source": "# Re-define the function that determines whether to continue or not\ndef should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n    messages = state['messages']\n    last_message = messages[-1]\n    # If the LLM makes a tool call, then we route to the \"tools\" node\n    if last_message.tool_calls:\n        return \"tools\"\n    # Otherwise, we stop (reply to the user)\n    return END\n\n\n# Re-define the function that calls the model\ndef call_model(state: MessagesState):\n    messages = state['messages']\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}", "metadata": {"id": "8549539b-96d7-4f93-b863-5360d520bad1"}, "outputs": [], "execution_count": 25}, {"cell_type": "code", "source": "# Re-define a new graph with new tools\nworkflow = StateGraph(MessagesState)\n\n# Re-define the two nodes we will cycle between\nworkflow.add_node(\"agent\", call_model)\nworkflow.add_node(\"tools\", tool_node)\n\n# Set the entrypoint as `agent`\n# This means that this node is the first one called\nworkflow.add_edge(START, \"agent\")\n\n# add a conditional edge\nworkflow.add_conditional_edges(\n    # First, we define the start node. We use `agent`.\n    # This means these are the edges taken after the `agent` node is called.\n    \"agent\",\n    # Next, we pass in the function that will determine which node is called next.\n    should_continue,\n)\n\n# add a normal edge from `tools` to `agent`.\n# after `tools` is called, `agent` node is called next.\nworkflow.add_edge(\"tools\", 'agent')\n\n\n# Re-compile graph\napp = workflow.compile()", "metadata": {"id": "cfc8ff1e-e203-474c-924b-64d8a94958b4"}, "outputs": [], "execution_count": 26}, {"cell_type": "markdown", "source": "Ask the AI agent questions about interest rate. Review the response.\n\n \n- what is the interest rate for matt?\n\n- what is the interest rate for matt? explain how it was determined?\n\nNote that how the AI agent can uses _rag_llm tools, and the content in the published documents to provide risk and interest rate.\nFor reference, these documents can be found here. They were used to create embeddings and vecotr index.\n\n#### Write the query in the box and hit Enter and then continue running the next cells", "metadata": {"id": "a84e9d78-5278-438e-aa63-b47ed4cdf273"}}, {"cell_type": "code", "source": "human_query = input(\"Type a question and hit enter: \")", "metadata": {"id": "ddeb24a9-0081-4931-8c86-26c60c29c074"}, "outputs": [{"output_type": "stream", "name": "stdin", "text": "Type a question and hit enter:  what is the interest rate for matt? explain how it was determined?\n"}], "execution_count": 27}, {"cell_type": "code", "source": "# Use the runtime\nfinal_state = app.invoke(\n    #{\"messages\": [HumanMessage(content=\"what is the overall risk?\")]},\n    {\"messages\": [HumanMessage(content=human_query)]},\n    config={\"configurable\": {\"thread_id\": random.randint(1, 100)}}\n)\n\n#final_state[\"messages\"][-1].content\n\nfor m in final_state[\"messages\"]:\n    m.pretty_print()\n\n#Print final message\n#final_state[\"messages\"][-1].content", "metadata": {"id": "3aa1b80b-970f-403b-bf06-053585327885"}, "outputs": [{"name": "stdout", "text": "================================\u001b[1m Human Message \u001b[0m=================================\n\nwhat is the interest rate for matt? explain how it was determined?\n==================================\u001b[1m Ai Message \u001b[0m==================================\nTool Calls:\n  get_customer_info (wes1atGTg)\n Call ID: wes1atGTg\n  Args:\n    customer_id: matt\n=================================\u001b[1m Tool Message \u001b[0m=================================\nName: get_customer_info\n\n{\"credit_score\": 685, \"account_status\": \"closed\"}\n==================================\u001b[1m Ai Message \u001b[0m==================================\nTool Calls:\n  get_overall_risk_from_rag_llm (FLh7R0RV0)\n Call ID: FLh7R0RV0\n  Args:\n    credit_score: 685\n    account_status: closed\n=================================\u001b[1m Tool Message \u001b[0m=================================\nName: get_overall_risk_from_rag_llm\n\n To determine the risk for a credit score of 685 and an account status of \"Closed,\" we need to refer to the \"Bank Loan Overall Risk\" table provided.\n\nHere's the relevant part of the table:\n\n| Credit Score | Account Status | Overall Risk |\n|--------------|----------------|--------------|\n| 675 - 749    | Closed         | Medium       |\n\nGiven that the credit score of 685 falls within the range of 675 - 749 and the account status is \"Closed,\" the overall risk is determined to be \"Medium.\"\n\nTherefore, the risk for a credit score of 685 and an account status of \"Closed\" is \"Medium.\"\n==================================\u001b[1m Ai Message \u001b[0m==================================\nTool Calls:\n  get_interest_rate_from_rag_llm (40ryTeiLU)\n Call ID: 40ryTeiLU\n  Args:\n    overall_risk: Medium\n=================================\u001b[1m Tool Message \u001b[0m=================================\nName: get_interest_rate_from_rag_llm\n\n The interest rate for an overall risk categorized as \"Medium\" is 4.885%. This rate is determined based on the table provided, which outlines the interest rates for initiating a bank loan according to the customer's overall risk. The table specifies that a \"Medium\" overall risk corresponds to an interest rate of 4.885%.\n==================================\u001b[1m Ai Message \u001b[0m==================================\n\n The interest rate for Matt is 4.885%. This rate is determined based on the table provided, which outlines the interest rates for initiating a bank loan according to the customer's overall risk. The table specifies that a \"Medium\" overall risk corresponds to an interest rate of 4.885%.\n", "output_type": "stream"}], "execution_count": 28}, {"cell_type": "code", "source": "", "metadata": {"id": "4f5c1cd7-f7ea-427d-8e04-6627bcdec237"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "5a642ba5-5bc9-4746-82ab-541f3d954561"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "802e3518-0156-4350-b553-f819df068056"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "9cec3987-9978-4750-8dbd-7c8ea258feb9"}, "outputs": [], "execution_count": null}]}