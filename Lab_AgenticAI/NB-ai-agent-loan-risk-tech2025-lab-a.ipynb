{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4be62f6a-4776-4dc9-b6db-9673f06bc388"
   },
   "source": [
    "# Tech 2025 Lab\n",
    "### Lab A - Loan Risk AI Agent\n",
    "An **AI Agent** refers to a system or program that is capable completing a request by first planning the sequence of workflow steps and then performing the tasks in the steps by utilizing available tools. AI agents utilizes large language models (LLM) to understand the context of the request, plan and perform the tasks. \n",
    "\n",
    "This Python Notebook provides the code to create a simple AI agent for risk and interest rate evaluation in a bank loan processing scenario. It uses LangGraph graph for state and runtime processing. Once created, you assume the persona of a loan risk analyst at a bank and ask the Loan Risk AI Agent questions in natural language to assess risks for customers. When a question is asked, the AI agent will use a LLM to understand the context, determine the seqence of steps, and then complete the steps utilizing availble tools. The tools fetch customer information, credit score, account status and determine risk and interest rate. The sequence of steps, tool calling and final response can be reviewed in the output.\n",
    "\n",
    "#### To use this Notebook:\n",
    "\n",
    "Run each cell below one by one and make sure it completes successfully.\n",
    "\n",
    "When prompted for API key enter it in the box and hit Enter and then continue running the cells to initialize the code.\n",
    "\n",
    "Finally, when prompted enter your query and run the subsequent cells. Some example questions are provided.\n",
    "\n",
    "You may run/repeat the query cells by entering and trying different queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "609b3c27-f6dc-4daf-8101-7a3b38791717"
   },
   "source": [
    "#### Lab A - Exercise 1\n",
    "Below is an outline of the code. The code is set up in Python Notebook cells.\n",
    "\n",
    "1. Set up required libraries\n",
    "2. Define functions to get and check credentials\n",
    "3. Define tools that the AI agent can use\n",
    "4. Configure the LLM\n",
    "5. Define the LangGraph graph and functions for state and runtime processing.\n",
    "6. Show a visual representation of the graph - the AI agent with tools\n",
    "7. Use the AI agent - ask the AI agent risk related question\n",
    "8. Review the responses from AI agent risk\n",
    "\n",
    "#### Lab A - Exercise 2\n",
    "1. Add another tool that can provide interest rate.\n",
    "2. Use the AI agent - ask the AI agent risk and interest rate related question\n",
    "3. Review the responses from AI agent risk\n",
    "\n",
    "\n",
    "#### Lab A - Exercise 3 (Optional)\n",
    "1. Update the overall risk and interest rate tools to use RAG (retrieval augmented generation) pattern based query determine risk and interest rate.\n",
    "2. Use the AI agent - ask the AI agent risk and interest rate related question\n",
    "3. Review the responses from AI agent risk\n",
    "\n",
    "\n",
    "~TBD cell bookmarks for above. Example, not working.\n",
    "\n",
    "<a href='#lab_a_exercise_2'>Lab A - Exercise 2</a>\n",
    "\n",
    "[Lab A - Exercise 2](#lab_a_exercise_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "956b5a54-4eb6-424f-83cc-1f6c15af4aa4"
   },
   "source": [
    "### Lab A - Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1f742f2c-386c-4094-874a-9be788685811"
   },
   "source": [
    "#### 1. Set up required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ac1bb4df-737d-45fb-9e14-6bdc75bad441",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph==0.2.73\n",
      "  Downloading langgraph-0.2.73-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.5/151.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting langgraph-sdk<0.2.0,>=0.1.42\n",
      "  Downloading langgraph_sdk-0.1.56-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43\n",
      "  Downloading langchain_core-0.3.44-py3-none-any.whl (415 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.7/415.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting langgraph-checkpoint<3.0.0,>=2.0.10\n",
      "  Downloading langgraph_checkpoint-2.0.19-py3-none-any.whl (39 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (24.2)\n",
      "Collecting langsmith<0.4,>=0.1.125\n",
      "  Downloading langsmith-0.3.13-py3-none-any.whl (339 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m339.7/339.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3.0.0,>=2.5.2\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.73) (4.12.2)\n",
      "Collecting PyYAML>=5.3\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-macosx_10_9_x86_64.whl (184 kB)\n",
      "Collecting msgpack<2.0.0,>=1.1.0\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-macosx_10_9_x86_64.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson>=3.10.1\n",
      "  Using cached orjson-3.10.15-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
      "Collecting httpx>=0.25.2\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Collecting anyio\n",
      "  Using cached anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Collecting certifi\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Collecting idna\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting requests<3,>=2\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-macosx_10_9_x86_64.whl (788 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.7/788.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Using cached pydantic_core-2.27.2-cp310-cp310-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl (198 kB)\n",
      "Collecting sniffio>=1.1\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.73) (1.2.2)\n",
      "Installing collected packages: zstandard, urllib3, tenacity, sniffio, PyYAML, pydantic-core, orjson, msgpack, jsonpointer, idna, h11, charset-normalizer, certifi, annotated-types, requests, pydantic, jsonpatch, httpcore, anyio, requests-toolbelt, httpx, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph\n",
      "Successfully installed PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.8.0 certifi-2025.1.31 charset-normalizer-3.4.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.44 langgraph-0.2.73 langgraph-checkpoint-2.0.19 langgraph-sdk-0.1.56 langsmith-0.3.13 msgpack-1.1.0 orjson-3.10.15 pydantic-2.10.6 pydantic-core-2.27.2 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 urllib3-2.3.0 zstandard-0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-ibm==0.3.6\n",
      "  Downloading langchain_ibm-0.3.6-py3-none-any.whl (25 kB)\n",
      "Collecting ibm-watsonx-ai<2.0.0,>=1.1.16\n",
      "  Downloading ibm_watsonx_ai-1.3.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchain-core<0.4,>=0.3.0 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from langchain-ibm==0.3.6) (0.3.44)\n",
      "Collecting pandas<2.2.0,>=0.24.2\n",
      "  Using cached pandas-2.1.4-cp310-cp310-macosx_10_9_x86_64.whl (11.7 MB)\n",
      "Collecting httpx<=0.28,>=0.27\n",
      "  Downloading httpx-0.28.0-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m817.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (2.32.3)\n",
      "Collecting ibm-cos-sdk<2.14.0,>=2.12.0\n",
      "  Using cached ibm-cos-sdk-2.13.6.tar.gz (58 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: certifi in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (2025.1.31)\n",
      "Requirement already satisfied: packaging in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (24.2)\n",
      "Collecting importlib-metadata\n",
      "  Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: urllib3 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (2.3.0)\n",
      "Collecting lomond\n",
      "  Using cached lomond-0.3.3-py2.py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (2.10.6)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (0.3.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (9.0.0)\n",
      "Requirement already satisfied: anyio in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from httpx<=0.28,>=0.27->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from httpx<=0.28,>=0.27->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from httpx<=0.28,>=0.27->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<=0.28,>=0.27->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (0.14.0)\n",
      "Collecting ibm-cos-sdk-core==2.13.6\n",
      "  Using cached ibm-cos-sdk-core-2.13.6.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ibm-cos-sdk-s3transfer==2.13.6\n",
      "  Using cached ibm-cos-sdk-s3transfer-2.13.6.tar.gz (139 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jmespath<=1.0.1,>=0.10.0\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from ibm-cos-sdk-core==2.13.6->ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (2.9.0.post0)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.2-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (3.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (0.23.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (1.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (3.10.15)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Collecting numpy<2,>=1.22.4\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-ibm==0.3.6) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from requests->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (3.4.1)\n",
      "Collecting zipp>=3.20\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from lomond->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from anyio->httpx<=0.28,>=0.27->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/varunojha/Documents/Varun/git/ibm/tech25/venv/lib/python3.10/site-packages (from anyio->httpx<=0.28,>=0.27->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm==0.3.6) (1.3.1)\n",
      "Installing collected packages: pytz, zipp, tzdata, tabulate, requests, numpy, lomond, jmespath, pandas, importlib-metadata, ibm-cos-sdk-core, httpx, ibm-cos-sdk-s3transfer, ibm-cos-sdk, ibm-watsonx-ai, langchain-ibm\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "\u001b[33m  DEPRECATION: ibm-cos-sdk-core is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for ibm-cos-sdk-core ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.28.1\n",
      "    Uninstalling httpx-0.28.1:\n",
      "      Successfully uninstalled httpx-0.28.1\n",
      "\u001b[33m  DEPRECATION: ibm-cos-sdk-s3transfer is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for ibm-cos-sdk-s3transfer ... \u001b[?25ldone\n",
      "\u001b[33m  DEPRECATION: ibm-cos-sdk is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25h  Running setup.py install for ibm-cos-sdk ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed httpx-0.28.0 ibm-cos-sdk-2.13.6 ibm-cos-sdk-core-2.13.6 ibm-cos-sdk-s3transfer-2.13.6 ibm-watsonx-ai-1.3.0 importlib-metadata-8.6.1 jmespath-1.0.1 langchain-ibm-0.3.6 lomond-0.3.3 numpy-1.26.4 pandas-2.1.4 pytz-2025.1 requests-2.32.2 tabulate-0.9.0 tzdata-2025.1 zipp-3.21.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Set up libraries\n",
    "%pip install langgraph==0.2.73\n",
    "%pip install -U langchain-ibm==0.3.6\n",
    "    \n",
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c376e0e3-76f0-4079-b382-995410034157"
   },
   "source": [
    "#### 2. Define functions to get and check credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "52a152ce-7efd-45f2-b5df-4ce5ea5efab7"
   },
   "outputs": [],
   "source": [
    "# Function to get credentials\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "# Get credentials\n",
    "# Set the Project IDs\n",
    "# If using you own account, or lab account and project, the current project id will be configured and set automtically\n",
    "_set_if_undefined(\"PROJECT_ID\")\n",
    "\n",
    "# When prompted for API key enter it in the box and hit Enter, move to next cell and then continue running the cells\n",
    "_set_if_undefined(\"WATSONX_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "069d3ba7-2788-4f3d-9083-df43c0495ff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Api key: BB4NAmMrgYOx69LIT869TXi1HkoToZlBsUPC2sagaybt\n",
      "Project id: d57fe1cd-2326-47a2-839f-d7cbd43967b8\n"
     ]
    }
   ],
   "source": [
    "# Print credential configurations for validation\n",
    "print('Api key:',os.environ.get(\"WATSONX_API_KEY\"))\n",
    "print('Project id:',os.environ.get(\"PROJECT_ID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb45e773-d3c9-42ca-b349-d062d808e596"
   },
   "source": [
    "#### 3. Define tools that the AI agent can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4aaf0378-a97b-4774-bc8d-855f75c9e3f9"
   },
   "outputs": [],
   "source": [
    "# Define tools that the AI agent can use\n",
    "\n",
    "# The tool get_customer_info() simulates/mocks API call that fetches credit score and account status information about a customer\n",
    "# The tools get_credit_score() and get_account_status() use the customer info tool to get the score and account status\n",
    "# The customer's loan risk is determined based on credit score and account status risk rules using get_overall_risk() tool\n",
    "# When a natural language question is asked, the AI agent first determines the context and then the sequence to utilize one or more tools to provide a response \n",
    "\n",
    "# this tool simulates an API call that will fetch information about customers\n",
    "@tool\n",
    "def get_customer_info(customer_id: str): \n",
    "    \"\"\"Retrieve customer information based on the customer_id.\"\"\"\n",
    "    customer_id = customer_id.lower()\n",
    "    \n",
    "    if customer_id in ['loren@ibm.com', 'loren', '1111']:\n",
    "        return {'credit_score': 455, 'account_status': 'good-standing'}\n",
    "    elif customer_id in ['matt@ibm.com', 'matt', '2222']:\n",
    "        return {'credit_score': 685, 'account_status': 'closed'}\n",
    "    elif customer_id in ['hilda@ibm.com', 'hilda', '3333']:\n",
    "        return {'credit_score': 825, 'account_status': 'delinquent'}\n",
    "    else:\n",
    "        #return {'credit_score': None, 'account_status': None}\n",
    "        #if any other customer id is used, provide a random credit score and account status\n",
    "        return {'credit_score': random.randint(300, 850), 'account_status': random.choice(['delinquent', 'good-standing', 'closed' ])}\n",
    "\n",
    "\n",
    "\n",
    "# this tool fetches credit score of a customer\n",
    "@tool\n",
    "def get_credit_score(customer_id: str) -> int: \n",
    "    \"\"\"Get the credit score for the customer using customer_id. Customer's name can be used instead of customer_id.\"\"\"\n",
    "    customer_info = get_customer_info(customer_id)\n",
    "    return customer_info['credit_score']\n",
    "    customer_id = customer_id.lower()\n",
    "\n",
    "\n",
    "# this tool fetches account status of a customer\n",
    "@tool\n",
    "def get_account_status(customer_id: str) -> str: \n",
    "    \"\"\"Get the account status for the customer using customer_id. Customer's name can be used instead of customer_id.\"\"\"\n",
    "    customer_info = get_customer_info(customer_id)\n",
    "    return customer_info['account_status']\n",
    "    customer_id = customer_id.lower()\n",
    "\n",
    "# this tool determines the overall risk for a customer\n",
    "@tool\n",
    "def get_overall_risk(credit_score: int, account_status: str):\n",
    "    \"\"\"Get overall risk based on combination of both credit score and account status. Only use high, medium or low as risk categories. Explain how the overall risk was calculated. If the credit score and account status are unknown then do not provide the risk status and first retrieve the missing credit score or account status.\"\"\"\n",
    "\n",
    "    #print(\"get_overall_risk():credit score:account status::\", credit_score, account_status)\n",
    "    \n",
    "    if (credit_score > 299 & credit_score < 674): \n",
    "        if (account_status == 'delinquent'): overall_risk = 'high'\n",
    "        elif (account_status == 'closed'):  overall_risk = 'high'\n",
    "        elif (account_status == 'good-standing'):  overall_risk = 'medium'\n",
    "        else: overall_risk = 'unkown'\n",
    "    \n",
    "    elif (credit_score >= 675 & credit_score < 749): \n",
    "        if (account_status == 'delinquent'): overall_risk = 'high'\n",
    "        elif (account_status == 'closed'):  overall_risk = 'medium'\n",
    "        elif (account_status == 'good-standing'):  overall_risk = 'medium'\n",
    "        else: overall_risk = 'unkown'\n",
    "\n",
    "    elif (credit_score >= 750 & credit_score < 851): \n",
    "        if (account_status == 'delinquent'): overall_risk = 'high'\n",
    "        elif (account_status == 'closed'):  overall_risk = 'low'\n",
    "        elif (account_status == 'good-standing'):  overall_risk = 'low'\n",
    "        else: overall_risk = 'unkown'\n",
    "    \n",
    "\n",
    "    else: overall_risk = 'unable to determine.'    \n",
    "    return overall_risk\n",
    "\n",
    "# Set the list of tools to be used by the AI agent\n",
    "tools = [get_credit_score, get_account_status, get_overall_risk, get_customer_info]\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "479bcf27-bfab-4602-9cbc-842311bb64c6"
   },
   "source": [
    "#### 4. Configure the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bbe66af5-01dd-44c2-9d61-c7cbc7758cf5"
   },
   "outputs": [],
   "source": [
    "#Configure the LLM\n",
    "\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames\n",
    "parameters = {\n",
    "    GenTextParamsMetaNames.DECODING_METHOD: \"sample\", #\"greedy\", #\"sample\"\n",
    "    GenTextParamsMetaNames.MIN_NEW_TOKENS: 150,\n",
    "    GenTextParamsMetaNames.MAX_NEW_TOKENS: 250,\n",
    "    GenTextParamsMetaNames.TEMPERATURE: 0,\n",
    "    #GenTextParamsMetaNames.TOP_K: 50,\n",
    "    #GenTextParamsMetaNames.TOP_P: 1,\n",
    "}\n",
    "\n",
    "from langchain_ibm import ChatWatsonx\n",
    "model = ChatWatsonx(\n",
    "    model_id=\"mistralai/mistral-large\", \n",
    "    #url=\"https://us-south.ml.cloud.ibm.com\", \n",
    "    url=\"https://eu-de.ml.cloud.ibm.com\", \n",
    "    apikey=os.environ.get(\"WATSONX_API_KEY\"),\n",
    "    project_id=os.environ.get(\"PROJECT_ID\"),\n",
    "    params=parameters,\n",
    ").bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a89083d-9436-45ff-851d-6c5698c8b0f7"
   },
   "source": [
    "#### 5. Define the LangGraph graph and functions for state and runtime processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "b2959dec-c28c-4ad5-82a0-d5ab8e33c8f8"
   },
   "outputs": [],
   "source": [
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fd9f88ac-fc71-4939-8f09-8e3e719450e4"
   },
   "outputs": [],
   "source": [
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "# add a normal edge from `tools` to `agent`.\n",
    "# after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"tools\", 'agent')\n",
    "\n",
    "\n",
    "# Compile graph\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d05e046a-8d73-4a29-aa78-6b1c89b563c5"
   },
   "source": [
    "#### 6. Show a visual representation of the graph - the AI agent with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "225b9451-fed0-4e61-9157-66ac42a0468d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "from IPython.display import display, Image\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6f8e1264-ad9d-43b1-a0f6-fc41292de435"
   },
   "source": [
    "#### 7. Use the AI agent - ask the AI agent risk related question\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb5074ac-de5c-4cc9-ac2c-76b9fd92a900"
   },
   "source": [
    "\n",
    "Ask the AI agent these questions. Review the response.\n",
    "\n",
    "- what can you do for me?\n",
    "- what can you do for me? how?\n",
    "\n",
    "- what is the risk for matt?\n",
    " \n",
    "- what is the risk for matt? explain why?\n",
    "\n",
    "- tell me about hilda?\n",
    "  \n",
    "- what is the risk for hilda? explain why?\n",
    "\n",
    "- what is the risk for credit score 774 and account status delinquent?\n",
    "\n",
    "- what is the risk for credit score 774 and account status delinquent? how was it determined?\n",
    "\n",
    "Also try asking questions about interest rate....\n",
    "\n",
    "- what is the interest rate for matt?\n",
    "\n",
    "- what is the interest rate for matt? explain how it was determined?\n",
    "\n",
    "For the last two questions, note that there is no tool yet that provides interest rate. So the response does not answer the question appropriately. \n",
    "We will add interest rate tool in the next exercise.\n",
    "\n",
    "#### Write the query in the box and hit Enter and then continue running the next cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ca269a6f-1ab0-4950-b27b-5101e52f052b"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type a question and hit enter:  what is the interest rate for matt? explain how it was determined?\n"
     ]
    }
   ],
   "source": [
    "human_query = input(\"Type a question and hit enter: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "053a334b-5f12-4a92-ab05-7e22e84219c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is the interest rate for matt? explain how it was determined?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_customer_info (0gEdZwXvA)\n",
      " Call ID: 0gEdZwXvA\n",
      "  Args:\n",
      "    customer_id: matt\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_customer_info\n",
      "\n",
      "{\"credit_score\": 685, \"account_status\": \"closed\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_overall_risk (SE92znhWL)\n",
      " Call ID: SE92znhWL\n",
      "  Args:\n",
      "    credit_score: 685\n",
      "    account_status: closed\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_overall_risk\n",
      "\n",
      "high\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      " The overall risk for Matt is high. This is determined by considering both the credit score and account status. A credit score of 685 is considered fair, and a closed account status indicates potential issues with the account. Combining these factors results in a high overall risk.\n"
     ]
    }
   ],
   "source": [
    "# Use the runtime\n",
    "final_state = app.invoke(\n",
    "    #{\"messages\": [HumanMessage(content=\"what is the overall risk?\")]},\n",
    "    {\"messages\": [HumanMessage(content=human_query)]},\n",
    "    config={\"configurable\": {\"thread_id\": random.randint(1, 100)}}\n",
    ")\n",
    "\n",
    "#final_state[\"messages\"][-1].content\n",
    "\n",
    "for m in final_state[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "\n",
    "#Print final message\n",
    "#final_state[\"messages\"][-1].content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a14b6c66-53f5-4730-8428-24b398177176"
   },
   "source": [
    "#### 8. Review the response above from AI agent risk\n",
    "Run/repeat the above cells with different queries, i.e., rerun the human_query and final_state = app.invoke() cells with different queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6984b533-9b55-4e89-9bd2-75517e26e4cc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3900ccac-113d-4877-82c3-68690f7f3bc7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7207c88a-163e-4759-9c1f-c23a87ef6f32"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdc2ebe1-36d1-4b66-83cd-6d8801a8dfb7"
   },
   "source": [
    "<a id='lab_a_exercise_2'></a>\n",
    "### Lab A - Exercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d00f3964-30f8-4451-89b6-46fb5a9ba8fe"
   },
   "source": [
    "So far we had tool that provided the risk level for a customer - as low, medium or high. There was no tool to provide a specific interest rate.\n",
    "In this exercise we will add another tool that can provide the interest rate based on the risk level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "907303b3-dbf0-42ec-9ba1-65c4d57a7004"
   },
   "outputs": [],
   "source": [
    "# this tool determines the interest rate for a customer\n",
    "@tool\n",
    "def get_interest_rate(overall_risk: str):\n",
    "    \"\"\"Get interest rate percentage based on the overall risk. If the overall risk is not known then do not provide the interest rate and first retrieve the missing overall risk.\"\"\"\n",
    "    if (overall_risk.lower() == \"high\"):\n",
    "        interest_rate=10.75;\n",
    "    \n",
    "    elif (overall_risk.lower() == \"medium\"):\n",
    "        interest_rate=5.25;\n",
    "\n",
    "    elif (overall_risk.lower() == \"low\"):\n",
    "        interest_rate=3.0;\n",
    "    \n",
    "    else: interest_rate = 'unable to determine.'    \n",
    "    return interest_rate\n",
    "\n",
    "\n",
    "# Lets add/include this tool in the list of tools used by the AI agent in the following code line \"tools =...\"\n",
    "tools = [get_credit_score, get_account_status, get_overall_risk, get_interest_rate, get_customer_info]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "83b40917-602b-4725-8b64-799788371f55"
   },
   "outputs": [],
   "source": [
    "# Re-bind the model configuration with new tools\n",
    "\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames\n",
    "parameters = {\n",
    "    GenTextParamsMetaNames.DECODING_METHOD: \"sample\", #\"greedy\", #\"sample\"\n",
    "    GenTextParamsMetaNames.MIN_NEW_TOKENS: 150,\n",
    "    GenTextParamsMetaNames.MAX_NEW_TOKENS: 250,\n",
    "    GenTextParamsMetaNames.TEMPERATURE: 0,\n",
    "    #GenTextParamsMetaNames.TOP_K: 50,\n",
    "    #GenTextParamsMetaNames.TOP_P: 1,\n",
    "}\n",
    "\n",
    "from langchain_ibm import ChatWatsonx\n",
    "model = ChatWatsonx(\n",
    "    model_id=\"mistralai/mistral-large\", \n",
    "    url=\"https://us-south.ml.cloud.ibm.com\", \n",
    "    #url=\"https://eu-de.ml.cloud.ibm.com\", \n",
    "    apikey=os.environ.get(\"WATSONX_API_KEY\"),\n",
    "    project_id=os.environ.get(\"PROJECT_ID\"),\n",
    "    params=parameters,\n",
    ").bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "fa1564b2-b055-4c9c-8ed1-f7cdb037a74b"
   },
   "outputs": [],
   "source": [
    "# Re-define the function that determines whether to continue or not\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "\n",
    "# Re-define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "9803104c-883a-419a-b727-d5b809c22ce8"
   },
   "outputs": [],
   "source": [
    "# Re-define a new graph with new tools\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Re-define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "# add a normal edge from `tools` to `agent`.\n",
    "# after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"tools\", 'agent')\n",
    "\n",
    "\n",
    "# Re-compile graph\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bbd99ea-9163-4e69-a238-cd9bd70b1dd9"
   },
   "source": [
    "\n",
    "Ask the AI agent questions about interest rate. Review the response.\n",
    "\n",
    " \n",
    "- what is the interest rate for matt?\n",
    "\n",
    "- what is the interest rate for matt? explain how it was determined?\n",
    "\n",
    "Note that how the AI agent can now use the get_interest_rate to provide interest rate also.\n",
    "\n",
    "#### Write the query in the box and hit Enter and then continue running the next cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "5799519a-abd5-47cd-b394-35e0554cc744"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type a question and hit enter:  what is the interest rate for matt? explain how it was determined?\n"
     ]
    }
   ],
   "source": [
    "human_query = input(\"Type a question and hit enter: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "f9551a68-cd7e-44ab-b820-64e266ad3611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is the interest rate for matt? explain how it was determined?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_customer_info (MxwzVlSyy)\n",
      " Call ID: MxwzVlSyy\n",
      "  Args:\n",
      "    customer_id: matt\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_customer_info\n",
      "\n",
      "{\"credit_score\": 685, \"account_status\": \"closed\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_overall_risk (cyhA7Rzsg)\n",
      " Call ID: cyhA7Rzsg\n",
      "  Args:\n",
      "    credit_score: 685\n",
      "    account_status: closed\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_overall_risk\n",
      "\n",
      "high\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_interest_rate (8S8EUh32D)\n",
      " Call ID: 8S8EUh32D\n",
      "  Args:\n",
      "    overall_risk: high\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_interest_rate\n",
      "\n",
      "10.75\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      " The interest rate for Matt is 10.75%. This was determined based on the overall risk assessment, which was categorized as high. The high risk category was assigned due to a credit score of 685 and a closed account status.\n"
     ]
    }
   ],
   "source": [
    "# Use the runtime\n",
    "final_state = app.invoke(\n",
    "    #{\"messages\": [HumanMessage(content=\"what is the overall risk?\")]},\n",
    "    {\"messages\": [HumanMessage(content=human_query)]},\n",
    "    config={\"configurable\": {\"thread_id\": random.randint(1, 100)}}\n",
    ")\n",
    "\n",
    "#final_state[\"messages\"][-1].content\n",
    "\n",
    "for m in final_state[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "\n",
    "#Print final message\n",
    "#final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d606aec0-2b2f-4cef-b56a-73dddf56a464"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10e0c369-ead5-45ac-9b3c-c0ee10f3243a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "686c3630-b75c-4c25-8b01-1613b20c82e1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3ccbc0f-be1a-43ca-82e6-5c217a747a0b"
   },
   "source": [
    "### Lab A - Exercise 3 (Optional) \n",
    "\n",
    "### ***** this exercise will be made demo only due to time constraints and complexities in creating RAG deployments and endpoints in every project ****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2f8a9074-1bee-406e-b0b8-af12c26a963d"
   },
   "source": [
    "In this exercise will use RAG (retrieval augmented generation) pattern based query determine risk and interest rate. Instead of conditions defined in the tool,  content in the published risk and interest rate documents will be used to determine the risk and interest rate. \n",
    "For reference, these documents can be found here. They were used to create embeddings and vector index for RAG querying.\n",
    "The RAG URL endpoint to get risk and interest rate was pre-created and will be called from the new tools.\n",
    "\n",
    "IN the following cells, we will create new rag llm based risk and interest rate tools and set up the AI agent to use them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "085d2e79-df7e-46c6-be8b-8b22c39a4f7c"
   },
   "outputs": [],
   "source": [
    "# Calling the RAG LLM endpoint requires a bearer token. First we will create the code that will be used to get the IBM IAM bearer token from API key\n",
    "# Function to get IBM IAM bearer token\n",
    "os.environ[\"IBM_IAM_ACCESS_TOKEN_EXPIRATION\"]=\"1\" #must be initialized for validaiton purposes\n",
    "def get_ibm_iam_token() -> str: \n",
    "    epoch_time = int(time.time())\n",
    "    #print(epoch_time)\n",
    "    if ( int(os.environ[\"IBM_IAM_ACCESS_TOKEN_EXPIRATION\"]) < epoch_time):\n",
    "        #print(\"IBM_IAM_ACCESS_TOKEN expired.\")\n",
    "    \n",
    "        #get new token\n",
    "        url = \"https://iam.cloud.ibm.com/identity/token\"\n",
    "        headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "        data = 'grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey='+os.environ.get(\"WATSONX_API_KEY\")\n",
    "        try:\n",
    "            response = requests.post(url, data=data, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            #print(response.json())\n",
    "            os.environ[\"IBM_IAM_ACCESS_TOKEN\"]=response.json()[\"access_token\"]\n",
    "            os.environ[\"IBM_IAM_ACCESS_TOKEN_EXPIRATION\"]=str(response.json()[\"expiration\"])\n",
    "    \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    #else:\n",
    "        #print(\"IBM_IAM_ACCESS_TOKEN is valid.\")\n",
    "        #print(\"IBM_IAM_ACCESS_TOKEN:\",os.environ[\"IBM_IAM_ACCESS_TOKEN\"])\n",
    "        #print(\"IBM_IAM_ACCESS_TOKEN_EXPIRATION:\",os.environ[\"IBM_IAM_ACCESS_TOKEN_EXPIRATION\"])\n",
    "\n",
    "    return os.environ[\"IBM_IAM_ACCESS_TOKEN\"]\n",
    "#print(get_ibm_iam_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "c007a959-b4d7-4577-b14b-c36f997e3431"
   },
   "outputs": [],
   "source": [
    "# this tool determines the overall risk for a customer using a RAG endpoint\n",
    "@tool\n",
    "def get_overall_risk_from_rag_llm(credit_score:int, account_status:str):\n",
    "    \"\"\"Get overall risk based on combination of both credit score and account status. Explain how the overall risk was calculated. If the credit score and account status are not known then do not provide the risk status and first retrieve the missing credit score or account status.\"\"\"\n",
    "    rag_url = \"https://us-south.ml.cloud.ibm.com/ml/v4/deployments/61b4776a-a77d-457e-b44d-c83a3b3456ad/ai_service?version=2021-05-01\"\n",
    "    headers = {'Content-type': 'application/json', 'Authorization': 'Bearer ' + get_ibm_iam_token() }\n",
    "    llm_rag_query=\"what is the risk for credit score \" + str(credit_score) + \" and account status \" + account_status + \", and how is it determined?\",\n",
    "    data = {\"messages\": [{\"content\": llm_rag_query,\"role\": \"user\" }]}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(rag_url, data=json.dumps(data), headers=headers)\n",
    "        response.raise_for_status()\n",
    "        #print(response.json())\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# this tool determines the interest rate for a customer using a RAG endpoint\n",
    "@tool\n",
    "def get_interest_rate_from_rag_llm(overall_risk:str):\n",
    "    \"\"\"Get interest rate percentage based on overall risk. If the overall risk is not known then do not provide the interest rate status and first retrieve the overall risk. Explain how the interest rate was determined.\"\"\"\n",
    "\n",
    "    rag_url = \"https://us-south.ml.cloud.ibm.com/ml/v4/deployments/61b4776a-a77d-457e-b44d-c83a3b3456ad/ai_service?version=2021-05-01\"\n",
    "    headers = {'Content-type': 'application/json', 'Authorization': 'Bearer ' + get_ibm_iam_token() }\n",
    "    llm_rag_query=\"what is the interest rate for overall risk \" + overall_risk + \", and how is it determined?\",\n",
    "    data = {\"messages\": [{\"content\": llm_rag_query,\"role\": \"user\" }]}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(rag_url, data=json.dumps(data), headers=headers)\n",
    "        response.raise_for_status()\n",
    "        #print(response.json())\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# Set the list of tools to be used by the AI agent - - we change the risk and interest rate tools to use the ones with rag_llm\n",
    "tools = [get_credit_score, get_account_status, get_overall_risk_from_rag_llm, get_interest_rate_from_rag_llm, get_customer_info]\n",
    "\n",
    "tool_node = ToolNode(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "e10f446a-8ba1-4401-9af2-4186db91a80e"
   },
   "outputs": [],
   "source": [
    "# Re-bind the model configuration with new tools\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames\n",
    "parameters = {\n",
    "    GenTextParamsMetaNames.DECODING_METHOD: \"sample\", #\"greedy\", #\"sample\"\n",
    "    GenTextParamsMetaNames.MIN_NEW_TOKENS: 150,\n",
    "    GenTextParamsMetaNames.MAX_NEW_TOKENS: 250,\n",
    "    GenTextParamsMetaNames.TEMPERATURE: 0,\n",
    "    #GenTextParamsMetaNames.TOP_K: 50,\n",
    "    #GenTextParamsMetaNames.TOP_P: 1,\n",
    "}\n",
    "\n",
    "from langchain_ibm import ChatWatsonx\n",
    "model = ChatWatsonx(\n",
    "    model_id=\"mistralai/mistral-large\", \n",
    "    url=\"https://us-south.ml.cloud.ibm.com\", \n",
    "    #url=\"https://eu-de.ml.cloud.ibm.com\", \n",
    "    apikey=os.environ.get(\"WATSONX_API_KEY\"),\n",
    "    project_id=os.environ.get(\"PROJECT_ID\"),\n",
    "    params=parameters,\n",
    ").bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8549539b-96d7-4f93-b863-5360d520bad1"
   },
   "outputs": [],
   "source": [
    "# Re-define the function that determines whether to continue or not\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "\n",
    "# Re-define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "cfc8ff1e-e203-474c-924b-64d8a94958b4"
   },
   "outputs": [],
   "source": [
    "# Re-define a new graph with new tools\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Re-define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "# add a normal edge from `tools` to `agent`.\n",
    "# after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"tools\", 'agent')\n",
    "\n",
    "\n",
    "# Re-compile graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a84e9d78-5278-438e-aa63-b47ed4cdf273"
   },
   "source": [
    "Ask the AI agent questions about interest rate. Review the response.\n",
    "\n",
    " \n",
    "- what is the interest rate for matt?\n",
    "\n",
    "- what is the interest rate for matt? explain how it was determined?\n",
    "\n",
    "Note that how the AI agent can uses _rag_llm tools, and the content in the published documents to provide risk and interest rate.\n",
    "For reference, these documents can be found here. They were used to create embeddings and vecotr index.\n",
    "\n",
    "#### Write the query in the box and hit Enter and then continue running the next cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ddeb24a9-0081-4931-8c86-26c60c29c074"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type a question and hit enter:  what is the interest rate for matt? explain how it was determined?\n"
     ]
    }
   ],
   "source": [
    "human_query = input(\"Type a question and hit enter: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3aa1b80b-970f-403b-bf06-053585327885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is the interest rate for matt? explain how it was determined?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_customer_info (wes1atGTg)\n",
      " Call ID: wes1atGTg\n",
      "  Args:\n",
      "    customer_id: matt\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_customer_info\n",
      "\n",
      "{\"credit_score\": 685, \"account_status\": \"closed\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_overall_risk_from_rag_llm (FLh7R0RV0)\n",
      " Call ID: FLh7R0RV0\n",
      "  Args:\n",
      "    credit_score: 685\n",
      "    account_status: closed\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_overall_risk_from_rag_llm\n",
      "\n",
      " To determine the risk for a credit score of 685 and an account status of \"Closed,\" we need to refer to the \"Bank Loan Overall Risk\" table provided.\n",
      "\n",
      "Here's the relevant part of the table:\n",
      "\n",
      "| Credit Score | Account Status | Overall Risk |\n",
      "|--------------|----------------|--------------|\n",
      "| 675 - 749    | Closed         | Medium       |\n",
      "\n",
      "Given that the credit score of 685 falls within the range of 675 - 749 and the account status is \"Closed,\" the overall risk is determined to be \"Medium.\"\n",
      "\n",
      "Therefore, the risk for a credit score of 685 and an account status of \"Closed\" is \"Medium.\"\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_interest_rate_from_rag_llm (40ryTeiLU)\n",
      " Call ID: 40ryTeiLU\n",
      "  Args:\n",
      "    overall_risk: Medium\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_interest_rate_from_rag_llm\n",
      "\n",
      " The interest rate for an overall risk categorized as \"Medium\" is 4.885%. This rate is determined based on the table provided, which outlines the interest rates for initiating a bank loan according to the customer's overall risk. The table specifies that a \"Medium\" overall risk corresponds to an interest rate of 4.885%.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      " The interest rate for Matt is 4.885%. This rate is determined based on the table provided, which outlines the interest rates for initiating a bank loan according to the customer's overall risk. The table specifies that a \"Medium\" overall risk corresponds to an interest rate of 4.885%.\n"
     ]
    }
   ],
   "source": [
    "# Use the runtime\n",
    "final_state = app.invoke(\n",
    "    #{\"messages\": [HumanMessage(content=\"what is the overall risk?\")]},\n",
    "    {\"messages\": [HumanMessage(content=human_query)]},\n",
    "    config={\"configurable\": {\"thread_id\": random.randint(1, 100)}}\n",
    ")\n",
    "\n",
    "#final_state[\"messages\"][-1].content\n",
    "\n",
    "for m in final_state[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "\n",
    "#Print final message\n",
    "#final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4f5c1cd7-f7ea-427d-8e04-6627bcdec237"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5a642ba5-5bc9-4746-82ab-541f3d954561"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "802e3518-0156-4350-b553-f819df068056"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cec3987-9978-4750-8dbd-7c8ea258feb9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tech25_venv",
   "language": "python",
   "name": "tech25_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
