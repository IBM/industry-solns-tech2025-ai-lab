{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# IBM Tech 2025 Lab\n\n\n## LAB B: RHELAI & InstructLab\n\n\nThis python notebook is a simple chatbot that uses the requests package to `chat` with a model served on a RHELAI VSI Instance using InstructLab.\n\nIf you are unfamiliar with Jupyter Notebook interface, you can quickly go through [documentation](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/notebook-editor.html?context=wx&locale=en&audience=wdp)\n\n### To use this Notebook:\nRun each cell below one by one and make sure it completes successfully.\n\nWhen prompted enter your query and hit Enter. Type 'exit' or 'quit' to terminate the chat loop and then manually select and continue running from next cell\n\nSome example questions are provided.\n\nYou may run/repeat the query cells by entering and trying different queries\n\n### Goals\n\n1) Chat with a model served on a RHELAI VSI using InstructLab VLLM\n2) Try a document summarization usecase using external assets\n3) Chat to expose some limitations of base mistral7b model\n4) Chat with a fine-tuned model that has been trained on synthetic generated data (SGD\n\n### LAB B - Exercise 1.a: \nBelow is an outline of the code. The code is set up in Python Notebook cells.\n\n1. Set up required libraries\n2. Set the variables for accessing the model server.\n3. Define the function to chat with model\n4. Chat with the model\n\n### LAB B - Exercise 1.b:\n1. Load your external data as assets\n2. Insert code snippet to read data\n3. Chat with the Model\n\n### LAB B - Exercise 2 & 3\n1. Review the Model Server URL\n2. Chat with the Model", "metadata": {"id": "110b3afc-90c5-4096-8973-b67fc3a4b6ec"}}, {"cell_type": "markdown", "source": "#### 1. Install Pre-requisite libraries", "metadata": {"id": "a315ca74-508e-470b-a705-c9f9b6672d38"}}, {"cell_type": "code", "source": "!pip install requests", "metadata": {"id": "fdc519dc-bfe2-4fc1-a396-030e8e04599b", "scrolled": true}, "outputs": [{"name": "stdout", "text": "Requirement already satisfied: requests in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (2.32.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests) (1.26.19)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests) (2025.1.31)\n", "output_type": "stream"}], "execution_count": 1}, {"cell_type": "code", "source": "import requests\nimport json\nimport getpass", "metadata": {"id": "f00890a3-1eee-4692-831d-7f8095c59e1a"}, "outputs": [], "execution_count": 2}, {"cell_type": "markdown", "source": "#### 2. Set the variables for accessing the model server", "metadata": {"id": "2e156ca4-f397-4968-b38f-0c8e75fab1fb"}}, {"cell_type": "code", "source": "# Define the model server URL (ensure it's correct for your deployment)\nMODEL_SERVER_URL = \"https://ilab-base.fs-demo.biz/v1/chat/completions\"\n\n# Securely get API key or authentication token if required\nAPI_KEY = \"popcorn-applies-flourish\"", "metadata": {"id": "ec270148-042e-4673-8cc7-4dceb7bdc129"}, "outputs": [], "execution_count": 3}, {"cell_type": "markdown", "source": "#### 3. Define function to chat with model using request package", "metadata": {"id": "3a52e96d-7077-4664-baa1-dd20f937ba62"}}, {"cell_type": "code", "source": "def chat_with_model(prompt):\n    headers = {\"Content-Type\": \"application/json\"}\n    if API_KEY:\n        headers[\"Authorization\"] = f\"Bearer {API_KEY}\"\n    \n    payload = {\n    \"model\": \"rhelai_service_model\",\n    \"messages\": [\n      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n      {\"role\": \"user\", \"content\": prompt}\n    ]\n    }\n    \n    try:\n        response = requests.post(MODEL_SERVER_URL, headers=headers, json=payload, verify=True)\n        response.raise_for_status()\n        data = response.json()\n        return data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"No response received.\")\n    except requests.exceptions.RequestException as e:\n        print(f\"Error: {e}\")\n        return f\"Error communicating with model: {e}\"\n", "metadata": {"id": "b061e89d-3571-464c-a26f-58205f2eff46"}, "outputs": [], "execution_count": 4}, {"cell_type": "markdown", "source": "#### 4. Provide a prompt to chat with the served model. Wait for response. Type 'exit' or 'quit' to terminate the chat loop and manually move to next cell.\n\n   Some sample prompts are\n   1) Hello, What can you do for me?\n   2) What are some of the good places to visit in Singapore?\n   3) What is the best way to travel around Singapore?\n   4) How hot does it get in Singapore during end of March and should i carry an umbrella?", "metadata": {"id": "9d2d07c2-5ceb-4b69-bc14-e2fdb3870236"}}, {"cell_type": "code", "source": "# Chat loop\nuser_input = \"\"\nwhile True:\n    user_input = input(\"You: Please input a prompt and hit enter\")\n    print(f\"Please wait....\")\n    if user_input.lower() in [\"exit\", \"quit\"]:\n        print(\"Exiting chat.\")\n        break\n    \n    response = chat_with_model(user_input)\n    print(f\"Model: {response}\")", "metadata": {"id": "b89fbf94-671d-45f2-8178-9f559ef3e568", "msg_id": "88f587d9-4e24-4e04-915e-55ea3268945e"}, "outputs": [{"output_type": "stream", "name": "stdin", "text": "You: Please input a prompt and hit enter What is IBM ?\n"}, {"name": "stdout", "text": "Please wait....\nError: 503 Server Error: Service Unavailable for url: https://ilab-base.fs-demo.biz/v1/chat/completions\nModel: Error communicating with model: 503 Server Error: Service Unavailable for url: https://ilab-base.fs-demo.biz/v1/chat/completions\n", "output_type": "stream"}], "execution_count": null}, {"cell_type": "markdown", "source": "### Exercise 1.b: Summarize documents\n\nLoad your external data as assets and use them in your queries. Here we will load the document into associated COS bucket first and then use its contents to form prompts.\n\nYou have two options\n\n1. Use the existing code by copy-pasting the below code block into new cell below\n\n```\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\n\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='pQT19GjBZoU33LeoUNiT-dAQf8osQUYpHdzs5lWwNQIR',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/identity/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.direct.us-south.cloud-object-storage.appdomain.cloud')\n\nbucket = 'rhelaiinstructlab-donotdelete-pr-tjhwbcblh1zk4y'\nobject_key = 'RES0217.txt'\n\n# load data of type \"text/plain\" into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n\nstreaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n```\n\n*OR*\n\n2. Follow the instructions at https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/load-and-access-data.html?context=wx&locale=en&audience=wdp to upload new data and insert code to read it.\n   1) From the toolbar, click the Upload asset to project icon (![Image](https://www.ibm.com/docs/en/SSQNUZ_5.1.x/wsj/console/images/find_data_icon.png)) and add your file (Text files upto 5KB).\n   2) Click the Code snippets icon ![Image](https://www.ibm.com/docs/en/SSQNUZ_5.1.x/wsj/analyze-data/images/code-snippets-icon.png), click _Read data_, and then _\"Select data from your project\"_, under _Data Asset_ category, find the file uploaded.\n   3) From the _Load as_ drop-down list, select the load option that you prefer(StreamingBody object). If you select Credentials, only file access credentials will be generated.\n   4) Click in an empty code cell in your notebook and then click _Insert code to cell_ to insert the generated code. Alternatively, click to _copy_ the generated code to the clipboard and then paste the code into your notebook.", "metadata": {"id": "c8f4c091-2012-431f-8621-53323c3e5908"}, "attachments": {}}, {"cell_type": "markdown", "source": "#### 5. Insert code snippet to read data", "metadata": {"id": "e8491f46-35a0-4ced-9dc5-ad0e0bb34bef"}}, {"cell_type": "code", "source": "", "metadata": {"id": "de061026-4c6d-4b4b-ab4b-ce09396744f5"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "#### 6. Review the document contents\nUpdate the document = &lt;variable&gt;.read() statement below with the variable into which body of the object is available (from last line of previous cell)", "metadata": {"id": "8b6a7810-2742-418e-ad3e-8d96971a4523"}}, {"cell_type": "code", "source": "document = streaming_body_1.read()\nprint(f\"Document read is \\n {document.decode('utf-8')}\")", "metadata": {"id": "bc162f3e-8607-4074-a0e3-abb7e9267b69"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "#### 7. Use the document read and prompt with it.\n  \nSample Prompts:\n\n1) This is a conversation between a doctor and patient, provide a diagnosis and plan the next steps. Explain your response.\n2) This is a conversation between a doctor and patient, is there an emergency involved or does this situation need immediate medical attention?\n3) Based on the above conversation between a doctor and patient, what are the major concerns discussed and course of treatment advised.", "metadata": {"id": "11481e96-e1bc-490d-a716-97021eb4077d"}}, {"cell_type": "code", "source": "# Chat loop\nwhile True:\n    user_input = input(\"You: Input a promt and hit Enter\")\n    print(f\"Please wait....\")\n    if user_input.lower() in [\"exit\", \"quit\"]:\n        print(\"Exiting chat.\")\n        break\n    \n    response = chat_with_model(f\"{document} \\n {user_input}\")\n    print(f\"Model: {response}\")", "metadata": {"id": "bd71f5f7-240c-40ad-b92b-6dee1fdde909", "scrolled": true}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "### Exercise 2: Ask about IBM Cloud for Financial Services\n\nThe base model is not trained on IBM Cloud for financial services and starts to hallucinate. Prompt to ask about FSCloud\n\nSample Prompts\n1) What is IBM FSCloud and what industry clients is it focussed at?\n   > Expected: IBM Cloud for Financial Services is a public cloud environment designed to support the needs of the financial services industry for mission-critical workloads and data protection. It offers compliance capabilities and industry-leading security to help reduce risk for financial institutions, their partners, and FinTechs. \n2) The security control requirements of IBM Cloud for Financial services are based on what?\n   > Expected: IBM Cloud for Financial Services is based on 565 control requirements, which are defined in the Control Requirements file. The controls are mapped to various standards such as NIST800-53, ISO 27001, ISO 27017, ISO 27018, and CSA Star.\n3) What is IBM Cloud for Financial Services Validated?\n   > Expected:IBM Cloud for Financial Services Validated refers to a service that has successfully completed the FS Validation program. It is applicable to internal services, ISVs and vendor solutions and offerings.\n   \nNotice how the responses are vague and in some cases downright incorrect. The base model is hallucinating.", "metadata": {"id": "34ee7a0f-0743-432c-8f95-99e93c67f3ec"}}, {"cell_type": "markdown", "source": "#### 8. Set the endpoint for VSI instance serving base model and chat with the model", "metadata": {"id": "15bbdb35-0370-460b-a5f0-a15958423fee"}}, {"cell_type": "code", "source": "# Define the base model server URL (ensure it's correct for your deployment)\nMODEL_SERVER_URL = \"https://ilab-base.fs-demo.biz/v1/chat/completions\"", "metadata": {"id": "53fda5b8-f167-4aa9-8a0a-cf346f96070e"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "# Chat loop\nwhile True:\n    user_input = input(\"You: Please input a prompt and hit Enter\")\n    print(f\"Please wait....\")\n    if user_input.lower() in [\"exit\", \"quit\"]:\n        print(\"Exiting chat.\")\n        break\n    \n    response = chat_with_model(f\"{user_input}\")\n    print(f\"Model: {response}\")", "metadata": {"id": "0c7615e6-93b9-43ef-88a2-de56913f46e3", "scrolled": true}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "### Exercise 3: Fine-tuned model\n\nThe base model is fine-tuned on a knowledge base of fscloud. The fine-tuned model is served on a different endpoint. \n\nRepeat the prompts to learn about IBM Cloud for Financial Services.", "metadata": {"id": "52f4f2e9-ebc0-4138-a273-2b24bc731c79"}}, {"cell_type": "code", "source": "#### 9. Set the endpoint for VSI instance serving the fine tuned model and chat with the model", "metadata": {"id": "a5870ada-b7b1-4eda-86b3-1f4a6e07c6da"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "# Define the base model server URL (ensure it's correct for your deployment)\nMODEL_SERVER_URL = \"https://ilab-tuned.fs-demo.biz/v1/chat/completions\"", "metadata": {"id": "f01b0973-2093-49c1-b4e2-c29e0c8298ff"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "# Chat loop\nwhile True:\n    user_input = input(\"You: Please input a prompt and hit Enter\")\n    print(f\"Please wait....\")\n    if user_input.lower() in [\"exit\", \"quit\"]:\n        print(\"Exiting chat.\")\n        break\n    \n    response = chat_with_model(f\"{user_input}\")\n    print(f\"Model: {response}\")", "metadata": {"id": "1bd12077-d3a6-49f5-a8bf-65c97a5210be", "scrolled": true}, "outputs": [], "execution_count": null}]}